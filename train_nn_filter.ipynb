{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4vFySyZJg0S",
        "outputId": "35f425ab-988c-4706-c48e-593af439eedc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "torch.cuda.empty_cache()\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "seed = 1234\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# # ------- UNCOMMENT IF USING COLAB ----\n",
        "# # Mount google drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Update path to import from Drive\n",
        "# import sys\n",
        "# dir_path = '/content/drive/MyDrive/HybridFilters/'\n",
        "# sys.path.append(dir_path) # path to folder in drive\n",
        "\n",
        "# device = 'cuda:0'\n",
        "# # ------------------------------------\n",
        "\n",
        "dir_path = os.getcwd()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bg26A0nnJn8W"
      },
      "outputs": [],
      "source": [
        "## --------------- LOAD DATA ----------------\n",
        "# Load numpy data\n",
        "N=128\n",
        "\n",
        "project_label = 'topHat8_valLaxSod50' # update to match the training data used\n",
        "\n",
        "filename_training = dir_path + '/training_data/disc_data_norm_siac0_syntheticTrainTophat8_testLaxSod484_valLaxSod50_LaxSodVal.npz'\n",
        "filename_validation = filename_training\n",
        "filename_test = filename_training \n",
        "\n",
        "# Training dataset\n",
        "data_file_training = np.load(filename_training)\n",
        "train_siac = data_file_training['disc_train']\n",
        "train_siac_exact = data_file_training['exact_train']\n",
        "\n",
        "# Validation dataset\n",
        "data_file_val = np.load(filename_validation)\n",
        "val_siac = data_file_val['disc_val']\n",
        "val_siac_exact = data_file_val['exact_val']\n",
        "\n",
        "# Test dataset\n",
        "data_file_test = np.load(filename_test)\n",
        "test_siac = data_file_test['disc_test']\n",
        "test_siac_exact = data_file_test['exact_test']\n",
        "\n",
        "# Selecting datasets\n",
        "train = train_siac\n",
        "train_exact = train_siac_exact\n",
        "val = val_siac\n",
        "val_exact = val_siac_exact\n",
        "test = test_siac\n",
        "test_exact = test_siac_exact\n",
        "plt_label = 'SIAC'\n",
        "\n",
        "# Convert to Torch tensor datasets\n",
        "batch = 200\n",
        "x_train = torch.tensor(train)\n",
        "y_train = torch.tensor(train_exact)\n",
        "train_ds = TensorDataset(x_train, y_train)\n",
        "train_dl = DataLoader(train_ds, batch_size=batch, shuffle=True)\n",
        "\n",
        "# x_val = torch.tensor(val)\n",
        "# y_val = torch.tensor(val_exact)\n",
        "\n",
        "# x_test = torch.tensor(test)\n",
        "# y_test = torch.tensor(test_exact)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGJ6cMkzKP8Q",
        "outputId": "321f98cc-2691-48ec-ddbc-d192c8062d00"
      },
      "outputs": [],
      "source": [
        "################ FILTER #########################\n",
        "## ---------------DEFINE & TRAIN FILTER ANN ----------------\n",
        "\n",
        "kernel = 7\n",
        "hidden_channels = 128\n",
        "num_layers = 7\n",
        "grid_length = 5000\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.leaky_relu_1= torch.nn.LeakyReLU(negative_slope=0.1)\n",
        "\n",
        "        self.conv_in = torch.nn.Conv1d(1, hidden_channels, kernel_size = kernel, padding='same', padding_mode='replicate')\n",
        "\n",
        "        self.conv2 = torch.nn.Conv1d(hidden_channels, hidden_channels, kernel_size = kernel, padding='same', padding_mode='replicate')\n",
        "        self.conv3 = torch.nn.Conv1d(hidden_channels, hidden_channels, kernel_size = kernel, padding='same', padding_mode='replicate')\n",
        "        self.conv4 = torch.nn.Conv1d(hidden_channels, hidden_channels, kernel_size = kernel, padding='same', padding_mode='replicate')\n",
        "        self.conv5 = torch.nn.Conv1d(hidden_channels, hidden_channels, kernel_size = kernel, padding='same', padding_mode='replicate')\n",
        "        self.conv6 = torch.nn.Conv1d(hidden_channels, hidden_channels, kernel_size = kernel, padding='same', padding_mode='replicate')\n",
        "\n",
        "        self.conv_out = torch.nn.Conv1d(hidden_channels, 1, kernel_size = kernel, padding='same', padding_mode='replicate')\n",
        "\n",
        "    def resnet(self, x):\n",
        "\n",
        "      x = self.leaky_relu_1(self.conv_in(x))\n",
        "\n",
        "      x = self.leaky_relu_1(self.conv2(x))\n",
        "      x = self.leaky_relu_1(self.conv3(x))\n",
        "      x = self.leaky_relu_1(self.conv4(x))\n",
        "      x = self.leaky_relu_1(self.conv5(x))\n",
        "      x = self.leaky_relu_1(self.conv6(x))\n",
        "\n",
        "      x = self.leaky_relu_1(self.conv_out(x))\n",
        "\n",
        "      return x\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      # Apply Data-driven, nonlinear NN filter with consistency\n",
        "      x_nn = x + self.resnet(x)\n",
        "\n",
        "      ones_vec = torch.ones(1,1,grid_length, device=device)\n",
        "      consistency = ones_vec + self.resnet(ones_vec)\n",
        "      constant = sum(consistency.view(-1))/grid_length\n",
        "\n",
        "      x_nn = x_nn/constant\n",
        "\n",
        "      return x_nn\n",
        "\n",
        "\n",
        "net = Net()\n",
        "net.to(device)\n",
        "\n",
        "pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
        "print(f'Number of trainable parameters: {pytorch_total_params}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQHDZhNTKoAm",
        "outputId": "10d593d4-b690-42c7-bfdf-0f9ef8628229"
      },
      "outputs": [],
      "source": [
        "# Vector for Consistency condition\n",
        "ones_vec = torch.ones(1,1,grid_length, device=device)\n",
        "half_window = 4\n",
        "pts_per_cell = 4\n",
        "mesh = np.linspace(-half_window, half_window+1, (2*half_window+1)*pts_per_cell)\n",
        "\n",
        "\n",
        "# Define Loss Function and Optimization method\n",
        "criterion_l2 = torch.nn.MSELoss()\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "# Saving Model\n",
        "dir = dir_path + '/' + project_label + '/'\n",
        "if not os.path.exists(dir):\n",
        "    os.makedirs(dir)\n",
        "\n",
        "filename = dir + \"B\" + str(batch) + \"_L\" + str(num_layers)+ \"_Ch\" + str(hidden_channels)+ \"_K\" + str(kernel) + \"_LR\" + \"{:5.1e}\".format(learning_rate)\n",
        "\n",
        "\n",
        "## ---------------TRAIN MODEL ----------------\n",
        "epochs = 500\n",
        "plot_loss_freq = 1\n",
        "training_loss_data = torch.zeros(epochs)\n",
        "validation_loss = torch.zeros(epochs)\n",
        "test_loss = torch.zeros(epochs)\n",
        "consistency = torch.zeros(epochs)\n",
        "best_epochs = []\n",
        "\n",
        "# *************UPDATE to previous best Validation Loss if training from Previous Model\n",
        "best_loss = np.inf\n",
        "\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_loss_data = 0.0\n",
        "    running_loss_moment = 0.0\n",
        "\n",
        "    if epoch ==0:\n",
        "        unfiltered_loss = 0.0\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    net.train()\n",
        "    for x_batch, y_batch in train_dl:\n",
        "\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        # Zero out the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Run forward step and compute loss\n",
        "        pred = net(x_batch.float())\n",
        "        true = y_batch.float()\n",
        "        loss = criterion_l2(pred, true)\n",
        "\n",
        "        # Run backpropagation and update the weights\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss_data += loss.detach().item()\n",
        "\n",
        "        if epoch == 0:\n",
        "            unfiltered = criterion_l2(x_batch.float(), y_batch.float())\n",
        "            unfiltered_loss += unfiltered.detach().item()\n",
        "\n",
        "        del x_batch\n",
        "        del y_batch\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_time = end_time - start_time\n",
        "\n",
        "    training_loss_data[epoch] = running_loss_data/len(train_dl)\n",
        "    consistency[epoch] = (sum(net(ones_vec).view(-1))/grid_length).detach().cpu()\n",
        "    unfiltered_plot = unfiltered_loss/len(train_dl)\n",
        "\n",
        "    net.eval()\n",
        "    loss_valid = 0.0\n",
        "    with torch.no_grad():\n",
        "\n",
        "        val_input = torch.FloatTensor(val).to(device)\n",
        "        val_output = torch.FloatTensor(val_exact).to(device)\n",
        "        filtered_val = net(val_input)\n",
        "        validation_loss[epoch] = criterion_l2(filtered_val, val_output).detach().item()\n",
        "\n",
        "        test_input = torch.FloatTensor(test).to(device)\n",
        "        test_output = torch.FloatTensor(test_exact).to(device)\n",
        "        filtered_test = net(test_input)\n",
        "        test_loss[epoch] = criterion_l2(filtered_test, test_output).detach().item()\n",
        "\n",
        "        if validation_loss[epoch] < best_loss:\n",
        "            best_loss = validation_loss[epoch]\n",
        "            torch.save(net.state_dict(), filename)\n",
        "\n",
        "            # Training Sample Figure\n",
        "            sample_id = 0\n",
        "            sample_input = train[sample_id, 0, :]\n",
        "            sample_exact = train_exact[sample_id, 0, :]\n",
        "            input = torch.FloatTensor(sample_input).view(1,1,-1).to(device)\n",
        "            filtered_input = net(input).detach().cpu()\n",
        "            filtered_input.detach().numpy()\n",
        "\n",
        "            plt.figure()\n",
        "            plt.plot(mesh, sample_input, '-s', label=plt_label)\n",
        "            plt.plot(mesh, filtered_input[0,0,:], '-o', label='NN Filter * '+plt_label)\n",
        "            plt.plot(mesh, sample_exact, '-k', label='Exact')\n",
        "            plt.title('Training Data (current best test loss model) at epoch'+str(epoch))\n",
        "            plt.xlabel('x')\n",
        "            plt.ylabel('Approx.')\n",
        "            plt.legend()\n",
        "            plt.savefig(filename + '_trainapprox.png')\n",
        "            plt.close()\n",
        "\n",
        "            # Validation Data Accuracy and Figure\n",
        "            plt.figure()\n",
        "            filtered_val = net(val_input).detach().cpu()\n",
        "            filtered_val.detach().numpy()\n",
        "            val_output = torch.FloatTensor(val_exact).to(\"cpu\")\n",
        "            val_output.detach().numpy()\n",
        "            val_id = 1\n",
        "            plt.plot(mesh, val[val_id, 0, :], '-s', label=plt_label)\n",
        "            plt.plot(mesh, filtered_val[val_id, 0, :], '-o', label='NN Filter * '+plt_label)\n",
        "            plt.plot(mesh, val_output[val_id, 0, :], '-k', label='Exact')\n",
        "            plt.title('Validation Data (current best val. loss model) at epoch'+str(epoch))\n",
        "            plt.xlabel('x')\n",
        "            plt.ylabel('Approx.')\n",
        "            plt.legend()\n",
        "            plt.savefig(filename + '_valapprox.png')\n",
        "            plt.close()\n",
        "\n",
        "            # Test Data Accuracy and Figure\n",
        "            plt.figure()\n",
        "            filtered_test = net(test_input).detach().cpu()\n",
        "            filtered_test.detach().numpy()\n",
        "            test_output = torch.FloatTensor(test_exact).to(\"cpu\")\n",
        "            test_output.detach().numpy()\n",
        "            test_id = 1\n",
        "            plt.plot(mesh, test[test_id, 0, :], '-s', label=plt_label)\n",
        "            plt.plot(mesh, filtered_test[test_id, 0, :], '-o', label='NN Filter * '+plt_label)\n",
        "            plt.plot(mesh, test_output[test_id, 0, :], '-k', label='Exact')\n",
        "            plt.title('Test Data (current best val. loss model) at epoch'+str(epoch))\n",
        "            plt.xlabel('x')\n",
        "            plt.ylabel('Approx.')\n",
        "            plt.legend()\n",
        "            plt.savefig(filename + '_testapprox.png')\n",
        "            plt.close()\n",
        "\n",
        "\n",
        "            print('epoch: ', epoch, '| unfiltered: ', \"{:5.2e}\".format(unfiltered_loss/len(train_dl)), '| train loss: ', \"{:5.2e}\".format(training_loss_data[epoch]),\n",
        "                  '| consistency: ', \"{:5.6e}\".format(consistency[epoch]), '| epoch_time = ', epoch_time, '| test loss: ', \"{:5.2e}\".format(test_loss[epoch]), '| validation loss: ', \"{:5.2e}\".format(validation_loss[epoch]), ' ***')\n",
        "            best_epochs.append(epoch)\n",
        "\n",
        "        else:\n",
        "            print('epoch: ', epoch, '| unfiltered: ', \"{:5.2e}\".format(unfiltered_loss/len(train_dl)), '| train loss: ', \"{:5.2e}\".format(training_loss_data[epoch]),\n",
        "                   '| consistency: ', \"{:5.6e}\".format(consistency[epoch]), '| epoch_time = ', epoch_time, '| test loss: ', \"{:5.2e}\".format(test_loss[epoch]), '| validation loss: ', \"{:5.2e}\".format(validation_loss[epoch]))\n",
        "\n",
        "        # Loss Figure\n",
        "        plt.figure()\n",
        "        plt.semilogy(plot_loss_freq*np.arange(epoch +1), unfiltered_plot*np.ones(epoch +1), '-', label=plt_label)\n",
        "        plt.semilogy(plot_loss_freq*np.arange(epoch +1), training_loss_data[:epoch+1], '-v', label='NN*'+plt_label+'- Training')\n",
        "        plt.semilogy(plot_loss_freq*np.arange(epoch + 1), validation_loss[:epoch+1], '-o', label='NN*'+plt_label+'- Validation')\n",
        "        plt.semilogy(plot_loss_freq*np.arange(epoch + 1), test_loss[:epoch+1], '-*', label='NN*'+plt_label+'- Test')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.savefig(filename + '_loss.png')\n",
        "        plt.close()\n",
        "\n",
        "        np.savez(filename, training=training_loss_data.detach().numpy(), validation=validation_loss.detach().numpy(), test=test_loss.detach().numpy(), epochs=best_epochs, consistency=consistency.detach().numpy())\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
